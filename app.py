import os
import sqlite3
import time
import requests
import subprocess
import sys
import atexit
import psutil
from flask import Flask, render_template, request, jsonify
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address
from dotenv import load_dotenv
from apscheduler.schedulers.background import BackgroundScheduler
from pydantic import BaseModel, ValidationError, Field
from typing import Optional

# Yerel modÃ¼ller
from core.ai_manager import AIManager
from core.fetcher import fetch_rss, process_missing_analysis, init_db
from core.logger import setup_logger
from core.cache import get_cache, set_cache

logger = setup_logger("App")

# .env dosyasÄ±ndaki deÄŸiÅŸkenleri yÃ¼kle
load_dotenv()

def auto_install_requirements():
    """requirements.txt dosyasÄ±ndaki baÄŸÄ±mlÄ±lÄ±klarÄ± kontrol eder ve eksik olanlarÄ± otomatik yÃ¼kler."""
    try:
        logger.info("ğŸ“¦ BaÄŸÄ±mlÄ±lÄ±klar kontrol ediliyor...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", "--disable-pip-version-check", "-r", "requirements.txt"])
    except Exception as e:
        logger.error(f"âŒ BaÄŸÄ±mlÄ±lÄ±k yÃ¼kleme hatasÄ±: {e}")

# Uygulama baÅŸlamadan Ã¶nce baÄŸÄ±mlÄ±lÄ±klarÄ± kontrol et
auto_install_requirements()

app = Flask(__name__)

# HÄ±z SÄ±nÄ±rlayÄ±cÄ± (Rate Limiter)
limiter = Limiter(
    get_remote_address,
    app=app,
    default_limits=["500 per day", "100 per hour"],
    storage_uri="memory://",
)

DB_PATH = 'data/sentinel.db'
ai_manager = AIManager()
start_time = time.time()


# --- Veri DoÄŸrulama Modelleri (Pydantic) ---
class AnalyzeRequest(BaseModel):
    title: str = Field(..., min_length=5)
    link: str

class CveRequest(BaseModel):
    id: str = Field(..., pattern=r'^CVE-\d{4}-\d+$')

class IpRequest(BaseModel):
    ip: str = Field(..., min_length=1)

class DnsRequest(BaseModel):
    domain: str = Field(..., min_length=3)


@app.route('/api/system/health', methods=['GET'])
def get_system_health():
    """Sunucu CPU ve RAM kullanÄ±m bilgilerini dÃ¶ner."""
    # cpu_percent(interval=0.1) ilk Ã§aÄŸrÄ±da 0 dÃ¶nmemesi iÃ§in kÄ±sa bir Ã¶lÃ§Ã¼m yapar
    return jsonify({
        "cpu": psutil.cpu_percent(interval=0.1),
        "ram": psutil.virtual_memory().percent,
        "uptime": int(time.time() - start_time)
    })

# Arka Plan GÃ¶revleri (Scheduler) YapÄ±landÄ±rmasÄ±

scheduler = BackgroundScheduler()
scheduler.add_job(func=fetch_rss, trigger="interval", minutes=15)
scheduler.add_job(func=process_missing_analysis, trigger="interval", minutes=5)
scheduler.start()

atexit.register(lambda: scheduler.shutdown())

def get_db_connection():
    """SQLite veritabanÄ±na baÄŸlantÄ± oluÅŸturur ve WAL modunu aktif eder."""
    conn = sqlite3.connect(DB_PATH, timeout=30)
    conn.execute("PRAGMA journal_mode=WAL")
    conn.row_factory = sqlite3.Row
    return conn

@app.route('/')
def index():
    """Ana sayfa dashboard arayÃ¼zÃ¼nÃ¼ yÃ¼kler."""
    return render_template('index.html')

@app.route('/api/ai_status', methods=['GET'])
def get_ai_status():
    """AI servislerinin durumunu ve bekleyen analiz sayÄ±sÄ±nÄ± dÃ¶ner."""
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("SELECT COUNT(*) FROM news WHERE ai_analysis IS NULL OR ai_analysis LIKE 'HATA:%'")
    pending = cursor.fetchone()[0]
    conn.close()
    
    status = ai_manager.get_status()
    status['pending_analysis'] = pending
    return jsonify(status)

@app.route('/api/news', methods=['GET'])
def get_news():
    """VeritabanÄ±ndaki haberleri sayfalama, arama ve kategori kriterlerine gÃ¶re getirir."""
    try:
        page = int(request.args.get('page', 1))
        search_query = request.args.get('search', '')
        category_filter = request.args.get('category', '')
        per_page = 10
        offset = (page - 1) * per_page

        conn = get_db_connection()
        cursor = conn.cursor()

        # Dinamik SQL sorgusu oluÅŸtur
        base_query = "SELECT * FROM news"
        count_query = "SELECT COUNT(*) FROM news"
        conditions = []
        params = []

        if search_query:
            conditions.append("title LIKE ?")
            params.append('%' + search_query + '%')
        
        if category_filter:
            conditions.append("category = ?")
            params.append(category_filter)

        where_clause = " WHERE " + " AND ".join(conditions) if conditions else ""
        
        # Toplam sayÄ±yÄ± al
        cursor.execute(count_query + where_clause, params)
        total_count = cursor.fetchone()[0]

        # Haberleri al
        cursor.execute(
            base_query + where_clause + " ORDER BY id DESC LIMIT ? OFFSET ?",
            params + [per_page, offset]
        )
        
        rows = cursor.fetchall()
        conn.close()
        
        return jsonify({
            "news": [dict(row) for row in rows],
            "total": total_count,
            "current_page": page,
            "per_page": per_page
        })
    except Exception as e:
        logger.error(f"Haber Ã§ekme hatasÄ±: {e}")
        return jsonify({"error": "Sistem hatasÄ±"}), 500

@app.route('/api/stats', methods=['GET'])
def get_stats():
    """Haberlerin kaynaklara gÃ¶re daÄŸÄ±lÄ±m istatistiklerini hesaplar."""
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("SELECT source, COUNT(*) as count FROM news GROUP BY source ORDER BY count DESC")
    sources = [dict(row) for row in cursor.fetchall()]
    conn.close()
    return jsonify({"sources": sources})

@app.route('/api/intensity', methods=['GET'])
def get_intensity():
    """Son 7 gÃ¼n iÃ§indeki haber giriÅŸ yoÄŸunluÄŸunu dÃ¶ner."""
    conn = get_db_connection()
    cursor = conn.cursor()
    cursor.execute("""
        SELECT date(COALESCE(created_at, CURRENT_TIMESTAMP)) as date, COUNT(*) as count 
        FROM news 
        WHERE created_at >= date('now', '-7 days') OR created_at IS NULL
        GROUP BY date
        ORDER BY date ASC
    """)
    intensity = [dict(row) for row in cursor.fetchall()]
    conn.close()
    return jsonify({"intensity": intensity})

@app.route('/api/stats/categories', methods=['GET'])
def get_category_stats():
    """Haberlerin tehdit kategorilerine gÃ¶re daÄŸÄ±lÄ±mÄ±nÄ± dÃ¶ner (FiltrelenmiÅŸ)."""
    conn = get_db_connection()
    cursor = conn.cursor()
    # Sadece kÄ±sa ve anlamlÄ± kategorileri getir (AI hatalÄ± parse etmiÅŸse temizle)
    cursor.execute("""
        SELECT category, COUNT(*) as count 
        FROM news 
        WHERE category IS NOT NULL 
        AND length(category) < 25
        GROUP BY category 
        ORDER BY count DESC
    """)
    stats = [dict(row) for row in cursor.fetchall()]
    conn.close()
    return jsonify({"categories": stats})

@app.route('/api/analyze', methods=['POST'])

def analyze_news_route():
    """Belirli bir haberi manuel olarak analiz eder (DoÄŸrulamalÄ±)."""
    try:
        # Pydantic ile veri doÄŸrula
        req_data = AnalyzeRequest(**request.json)
        
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT ai_analysis FROM news WHERE link = ?", (req_data.link,))
        existing = cursor.fetchone()
        
        if existing and existing[0] and not existing[0].startswith("HATA:"):
            conn.close()
            return jsonify({"analysis": existing[0]})

        prompt = (
            f"Analizine 'TEHDIT SEVIYESI: [KRITIK/ORTA/DUSUK]' ve 'KATEGORI: [Malware/Phishing/Ransomware/Vulnerability/Breach/General]' ile baÅŸla.\n"
            f"Haber: {req_data.title}\nLink: {req_data.link}"
        )
        analysis_result = ai_manager.analyze(prompt)

        if analysis_result and not analysis_result.startswith("HATA:"):
            # Kategoriyi ayÄ±kla ve doÄŸrula
            category = "General"
            valid_categories = ["Malware", "Phishing", "Ransomware", "Vulnerability", "Breach", "General"]
            
            if "KATEGORI:" in analysis_result:
                try: 
                    raw_cat = analysis_result.split("KATEGORI:")[1].split("]")[0].replace("[", "").strip()
                    # Whitelist kontrolÃ¼: EÄŸer Ã§Ä±kartÄ±lan kelime valid deÄŸilse "General" yap
                    found = False
                    for valid in valid_categories:
                        if valid.lower() in raw_cat.lower():
                            category = valid
                            found = True
                            break
                    if not found and len(raw_cat) > 20: # EÄŸer Ã§ok uzunsa muhtemelen hatalÄ± parse
                        category = "General"
                    elif not found:
                        category = raw_cat[:20] # Limit length
                except: pass
            
            cursor.execute("UPDATE news SET ai_analysis = ?, category = ? WHERE link = ?", 
                           (analysis_result, category, req_data.link))
            conn.commit()
        
        conn.close()
        return jsonify({"analysis": analysis_result})
    except ValidationError as e:
        return jsonify({"error": "GeÃ§ersiz veri formatÄ±", "details": e.errors()}), 400
    except Exception as e:
        logger.error(f"Manuel analiz hatasÄ±: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/cve', methods=['GET'])
@limiter.limit("10 per minute")
def analyze_cve_route():
    """CVE ID Ã¼zerinden istihbarat toplar ve AI ile teknik yorum ekler (Ã–nbellekli)."""
    try:
        cve_id = request.args.get('id', '').strip().upper()
        CveRequest(id=cve_id)

        # Ã–nbellek KontrolÃ¼
        cached_data = get_cache(f"cve_{cve_id}")
        if cached_data: return jsonify(cached_data)

        res = requests.get(f"https://cve.circl.lu/api/cve/{cve_id}", timeout=15)
        if res.status_code == 200:
            data = res.json()
            if not data: return jsonify({"error": "CVE bulunamadÄ±"}), 404
            
            summary = data.get('summary', 'AÃ§Ä±klama bulunamadÄ±.')
            cvss = data.get('cvss', 'Bilinmiyor')
            
            context = f"Ã–zet: {summary}" if summary != "AÃ§Ä±klama bulunamadÄ±." else f"{cve_id} Ã¶zelinde zafiyet yorumu yap."
            prompt = f"Siber gÃ¼venlik uzmanÄ± olarak analiz et:\nCVE: {cve_id}\nCVSS: {cvss}\n{context}"
            ai_comment = ai_manager.analyze(prompt)
            
            result = {
                "id": cve_id,
                "summary": summary,
                "cvss": cvss,
                "ai_comment": ai_comment,
                "references": data.get('references', [])[:5]
            }
            set_cache(f"cve_{cve_id}", result)
            return jsonify(result)
        return jsonify({"error": "DÄ±ÅŸ servis hatasÄ±"}), 502
    except ValidationError:
        return jsonify({"error": "GeÃ§ersiz CVE formatÄ± (Ã–rn: CVE-2024-1234)"}), 400
    except Exception as e:
        logger.error(f"CVE sorgu hatasÄ±: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/ip', methods=['GET'])
@limiter.limit("20 per minute")
def analyze_ip_route():
    """IP adresi Ã¼zerinden konum ve ISP istihbaratÄ± toplar (Ã–nbellekli)."""
    try:
        ip_addr = request.args.get('ip', '').strip()
        IpRequest(ip=ip_addr)

        # Ã–nbellek KontrolÃ¼
        cached_data = get_cache(f"ip_{ip_addr}")
        if cached_data: return jsonify(cached_data)

        res = requests.get(f"http://ip-api.com/json/{ip_addr}?fields=status,message,country,city,isp,org,as,query", timeout=10)
        if res.status_code == 200:
            data = res.json()
            if data['status'] == 'fail': return jsonify({"error": "IP bulunamadÄ±"}), 404
            
            result = {
                "ip": data['query'],
                "location": f"{data.get('city')}, {data.get('country')}",
                "isp": data.get('isp'),
                "org": data.get('org'),
                "as": data.get('as')
            }
            set_cache(f"ip_{ip_addr}", result)
            return jsonify(result)

        return jsonify({"error": "Servis ulaÅŸÄ±lamadÄ±"}), 502
    except ValidationError:
        return jsonify({"error": "GeÃ§ersiz IP adresi"}), 400
    except Exception as e:
        logger.error(f"IP sorgu hatasÄ±: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/dns', methods=['GET'])
def analyze_dns_route():
    """Verilen domain iÃ§in tÃ¼m kritik DNS kayÄ±tlarÄ±nÄ± sorgular."""
    try:
        domain = request.args.get('domain', '').strip()
        DnsRequest(domain=domain)

        import dns.resolver
        results = {"domain": domain, "records": {}}
        record_types = ['A', 'NS', 'CNAME', 'MX', 'TXT']
        
        for rtype in record_types:
            try:
                answers = dns.resolver.resolve(domain, rtype)
                results["records"][rtype] = [str(r) for r in answers]
            except:
                results["records"][rtype] = []

        if not any(results["records"].values()):
            return jsonify({"error": "KayÄ±t bulunamadÄ±"}), 404

        return jsonify(results)
    except ValidationError:
        return jsonify({"error": "GeÃ§ersiz domain adÄ±"}), 400
    except Exception as e:
        logger.error(f"DNS sorgu hatasÄ±: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/api/whois', methods=['GET'])
@limiter.limit("10 per minute")
def get_whois():
    """Domain iÃ§in WHOIS bilgilerini Ã§eker (GeliÅŸmiÅŸ hata yÃ¶netimi ve Ã¶nbellek)."""
    domain = request.args.get('domain', '').strip().lower()
    if not domain: return jsonify({"error": "Domain gerekli"}), 400
    
    # WHOIS sorgularÄ±nda kullanÄ±cÄ± talebiyle Ã¶nbellek kaldÄ±rÄ±ldÄ±

    import whois
    try:
        # BazÄ± sistemlerde whois komutu eksik olabilir, kÃ¼tÃ¼phane bunu yÃ¶netir
        w = whois.whois(domain)
        
        if not w or not any(w.values()):
            return jsonify({"error": "Whois kaydÄ± bulunamadÄ± veya domain geÃ§ersiz."}), 404

        # Tarih formatlarÄ±nÄ± dÃ¼zelt
        def format_date(d):
            if not d: return "Bilinmiyor"
            if isinstance(d, list): d = d[0]
            try:
                return d.strftime('%Y-%m-%d %H:%M:%S') if hasattr(d, 'strftime') else str(d)
            except:
                return str(d)

        # Name Server temizleme
        ns_list = []
        if w.name_servers:
            if isinstance(w.name_servers, list):
                ns_list = [str(ns).lower() for ns in w.name_servers if ns]
            else:
                ns_list = [str(w.name_servers).lower()]

        result = {
            "domain": domain,
            "registrar": (w.registrar[0] if isinstance(w.registrar, list) else w.registrar) or "Bilinmiyor",
            "creation_date": format_date(w.get('creation_date')),
            "expiration_date": format_date(w.get('expiration_date')),
            "name_servers": sorted(list(set(ns_list))),
            "status": (w.status[0] if isinstance(w.status, list) else w.status) or "Bilinmiyor"
        }
        set_cache(f"whois_{domain}", result)
        return jsonify(result)
    except Exception as e:
        logger.error(f"Whois HatasÄ± ({domain}): {e}")
        return jsonify({"error": f"Whois bilgisi alÄ±namadÄ±: {str(e)}"}), 500

@app.route('/api/analyze_all', methods=['POST'])
@limiter.limit("2 per hour")
def trigger_bulk_analysis():
    """Arka planda bekleyen tÃ¼m haberleri analiz eder."""
    scheduler.add_job(func=process_missing_analysis, trigger="date")
    return jsonify({"message": "Toplu analiz sÃ¼reci baÅŸlatÄ±ldÄ±."})

@app.route('/api/subdomains', methods=['GET'])
@limiter.limit("10 per minute")
def get_subdomains():
    """crt.sh Ã¼zerinden pasif subdomain keÅŸfi (Timeout ve Hata YÃ¶netimi)."""
    domain = request.args.get('domain', '').strip().lower()
    if not domain: return jsonify({"error": "Domain gerekli"}), 400
    
    # Subdomain keÅŸfinde kullanÄ±cÄ± talebiyle Ã¶nbellek kaldÄ±rÄ±ldÄ±

    try:
        # crt.sh bazen yavaÅŸ olabilir, timeout ekliyoruz
        url = f"https://crt.sh/?q=%25.{domain}&output=json"
        res = requests.get(url, timeout=20)
        
        if res.status_code == 200:
            try:
                data = res.json()
            except:
                return jsonify({"error": "crt.sh verisi okunamadÄ±."}), 502

            if not data:
                return jsonify({"error": f"{domain} iÃ§in hiÃ§bir sertifika kaydÄ± bulunamadÄ±."}), 404

            # Alt alan adlarÄ±nÄ± ayÄ±kla ve temizle
            subs = set()
            for entry in data:
                name = entry.get('name_value', '')
                # Ã‡oklu satÄ±r (wildcard vb) olanlarÄ± ayÄ±r
                for n in name.split('\n'):
                    n = n.strip().lower()
                    if n.endswith(domain) and n != domain and '*' not in n:
                        subs.add(n)
            
            if not subs:
                return jsonify({"error": "Alt alan adÄ± tespit edilemedi (Sadece ana domain kayÄ±tlÄ± olabilir)."}), 404

            result = {
                "domain": domain, 
                "subdomains": sorted(list(subs))[:100] # Ä°lk 100 tanesini sÄ±nÄ±rla
            }
            set_cache(f"subs_{domain}", result)
            return jsonify(result)
        return jsonify({"error": f"crt.sh servisi hata dÃ¶ndÃ¼rdÃ¼: {res.status_code}"}), 502
    except requests.exceptions.Timeout:
        return jsonify({"error": "Sorgu zaman aÅŸÄ±mÄ±na uÄŸradÄ± (crt.sh Ã§ok yavaÅŸ). LÃ¼tfen birazdan tekrar deneyin."}), 504
    except Exception as e:
        logger.error(f"Subdomain HatasÄ± ({domain}): {e}")
        return jsonify({"error": "BaÄŸlantÄ± hatasÄ± veya geÃ§ersiz veri."}), 500

if __name__ == '__main__':
    # VeritabanÄ±nÄ± kontrol et ve gerekirse tablolarÄ±/sÃ¼tunlarÄ± oluÅŸtur
    init_db()
    
    logger.info("ğŸš€ SentinelAi Sunucusu BaÅŸlatÄ±lÄ±yor...")
    app.run(host='0.0.0.0', port=5000, debug=True)

